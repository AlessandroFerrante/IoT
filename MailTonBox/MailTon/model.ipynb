{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_lk1xfgALbA",
        "outputId": "f96ca853-4740-4c8d-cc6e-47b67c3e68c7"
      },
      "outputs": [],
      "source": [
        "!pip install tinymlgen\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import normalize\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics.cluster import homogeneity_score\n",
        "from sklearn.metrics.cluster import completeness_score\n",
        "from sklearn.metrics.cluster import v_measure_score\n",
        "from google.colab import drive\n",
        "import random\n",
        "from google.colab import files\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "7ZPVWjh2AmVi",
        "outputId": "885da4c5-05be-4a44-8202-7024e90cc6f6"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Carica il file manualmente\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Leggi il file CSV (sostituisci 'nome_del_tuo_file.csv' con il vero nome del file)\n",
        "df = pd.read_csv(\"dataset.csv\")\n",
        "\n",
        "# Mostra le prime righe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "I5J-_tl3BLj8",
        "outputId": "fcc2efd7-4f38-486c-a8b3-ac9ec690915d"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "df['temp'].plot(kind='hist', bins=20, title='temp')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx5UaUdCB5ow",
        "outputId": "1450634c-1830-4c9a-ed2e-8ffe9e449c7d"
      },
      "outputs": [],
      "source": [
        "# Controlliamo informazioni generali\n",
        "print(df.info())\n",
        "\n",
        "# Controlliamo statistiche descrittive\n",
        "print(df.describe())\n",
        "\n",
        "# Controlliamo se ci sono valori mancanti\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UTegFyMyB9J0",
        "outputId": "00c514fb-a7d7-4799-baa0-3d181e29675e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns  # Import seaborn for heatmap\n",
        "\n",
        "# Assuming 'df' is your DataFrame, replace 'data' with 'df' in the following lines:\n",
        "# Convert specific columns to numeric before plotting\n",
        "for col in ['temp', 'humidity', 'ppm']:  # Add other relevant columns if needed\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')  # Use errors='coerce' to handle potential errors\n",
        "\n",
        "# Select only numerical features for correlation calculation\n",
        "numerical_data = df[['temp', 'humidity', 'ppm']]  # Include only numeric columns\n",
        "\n",
        "# Istogrammi delle feature numeriche\n",
        "df.hist(figsize=(10, 6), bins=20)  # Replace 'data' with 'df'\n",
        "plt.show()\n",
        "\n",
        "# Matrice di correlazione using numerical_data\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(numerical_data.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Matrice di Correlazione\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6pMGd3zKJL-"
      },
      "source": [
        "## Classificazione delle etichette e  o Normalizzazione con MinMaxScaler ***(input feature & target variable)***, KNN e trasformazione logaritmica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "phHeNh3oJy-3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.layers import Input, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Assuming 'df' is your dfFrame containing the df\n",
        "X = df[[\"temp\", \"humidity\"]].values\n",
        "y_reg = df[\"ppm\"].values  # Regression\n",
        "# Create a LabelEncoder object\n",
        "encoder_ppm = LabelEncoder()\n",
        "\n",
        "# Fit the encoder to your 'class_ppm' column (excluding the header) and transform it\n",
        "y_class_ppm = encoder_ppm.fit_transform(df[\"class_ppm\"][1:]) # Start from index 1 to exclude header\n",
        "\n",
        "# If you also want to encode 'temp_humidity_class'\n",
        "encoder_th = LabelEncoder()\n",
        "y_class_th = encoder_th.fit_transform(df[\"temp_humidity_class\"][1:]) # Start from index 1 to exclude header\n",
        "\n",
        "# Now proceed with train_test_split\n",
        "X_train, X_test, y_reg_train, y_reg_test, y_class_ppm_train, y_class_ppm_test, y_class_th_train, y_class_th_test = train_test_split(\n",
        "    X[1:], y_reg[1:], y_class_ppm, y_class_th, test_size=0.2, random_state=42\n",
        ") # Apply [1:] to X and y_reg as well to exclude the first row\n",
        "\n",
        "    # Prepare df for scaling\n",
        "X = df[[\"temp\", \"humidity\"]].values[1:]  # Exclude the header row\n",
        "y_reg = df[\"ppm\"].values[1:]  # Regression, exclude the header row\n",
        "\n",
        "# Scale input features and target variable using MinMaxScaler\n",
        "scaler_X = MinMaxScaler()  # For input features\n",
        "scaler_y = MinMaxScaler()  # For target variable\n",
        "\n",
        "X_train = scaler_X.fit_transform(X_train)\n",
        "X_test = scaler_X.transform(X_test)\n",
        "\n",
        "# Reshape y_reg_train and y_reg_test for scaling\n",
        "y_reg_train = y_reg_train.reshape(-1, 1)  # Reshape to 2D array\n",
        "y_reg_test = y_reg_test.reshape(-1, 1)  # Reshape to 2D array\n",
        "\n",
        "y_reg_train = scaler_y.fit_transform(y_reg_train)\n",
        "y_reg_test = scaler_y.transform(y_reg_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "SotXJSYwToUp",
        "outputId": "1520639e-1273-42cb-8cad-4bd755c123be"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Carica il file manualmente\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Leggi il file CSV (sostituisci 'nome_del_tuo_file.csv' con il vero nome del file)\n",
        "df = pd.read_csv(\"dataset.csv\")\n",
        "\n",
        "# Mostra le prime righe\n",
        "df.head()\n",
        "data = pd.read_csv(\"dataset.csv\", header=None)\n",
        "data.columns = [\"temp\", \"humidity\", \"ppm\", \"class_ppm\", \"temp_humidity_class\"]\n",
        "\n",
        "# Visualizza le prime righe per verificare\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVLVYPFRToUq",
        "outputId": "83a6d6ec-5a18-410a-b409-62b7f87c8d3a"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Seleziona solo le feature numeriche che vuoi scalare (escludendo le variabili target)\n",
        "features = ['temp', 'humidity']  # Changed: removed 'ppm'\n",
        "target_class = ['temp_humidity_class', 'class_ppm']  # Classi di classificazione\n",
        "\n",
        "# Inizializza lo scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Applica MinMaxScaler solo alle feature numeriche\n",
        "df_scaled = df.copy()\n",
        "df_scaled[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "# Verifica lo scaling\n",
        "print(df_scaled.head())\n",
        "\n",
        "# Ora dividi in X e Y per l'addestramento\n",
        "X = df_scaled[features]\n",
        "y_reg = df_scaled['ppm']  # Target di regressione (ppm)\n",
        "y_class1 = df_scaled['temp_humidity_class']  # Classificazione temp/humidity\n",
        "y_class2 = df_scaled['class_ppm']  # Classificazione ppm\n",
        "\n",
        "# Conversione delle classi in categorical per la rete neurale\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_class1 = to_categorical(y_class1)\n",
        "y_class2 = to_categorical(y_class2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YAJpKuBgToUr",
        "outputId": "41e75aa6-14fa-4dd5-8a4d-2084361352ca"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Concatenate, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from collections import Counter\n",
        "from numpy import argmax  # Import argmax for decoding one-hot encoded labels\n",
        "\n",
        "# Seleziona solo le feature numeriche che vuoi scalare (escludendo le variabili target)\n",
        "features = ['temp', 'humidity']  # Changed: removed 'ppm'\n",
        "target_class = ['temp_humidity_class', 'class_ppm']  # Classi di classificazione\n",
        "\n",
        "# Inizializza lo scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Applica MinMaxScaler solo alle feature numeriche\n",
        "df_scaled = df.copy()\n",
        "df_scaled[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "# Verifica lo scaling\n",
        "print(df_scaled.head())\n",
        "\n",
        "# Ora dividi in X e Y per l'addestramento\n",
        "X = df_scaled[features]\n",
        "y_reg = df_scaled['ppm']  # Target di regressione (ppm)\n",
        "y_class1 = df_scaled['temp_humidity_class']  # Classificazione temp/humidity\n",
        "y_class2 = df_scaled['class_ppm']  # Classificazione ppm\n",
        "\n",
        "# Conversione delle classi in categorical per la rete neurale\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_class1 = to_categorical(y_class1)\n",
        "y_class2 = to_categorical(y_class2)\n",
        "\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Bilancia le classi temp_humidity_class\n",
        "smote_th = SMOTE()\n",
        "X_resampled, y_class1_resampled = smote_th.fit_resample(X, argmax(y_class1, axis=1))  # Resample using argmax of y_class1\n",
        "y_class1_decoded = [argmax(label) for label in y_class1_resampled]  # Removed to_categorical\n",
        "print(\"Nuova distribuzione Temp-Humidity Class:\", Counter(y_class1_decoded))\n",
        "\n",
        "\n",
        "# Bilancia le classi class_ppm\n",
        "smote_ppm = SMOTE()\n",
        "X_resampled, y_class2_resampled = smote_ppm.fit_resample(X, argmax(y_class2, axis=1)) # Resample using argmax of y_class2\n",
        "y_class2_decoded = y_class2_resampled # Now y_class2_resampled contains the balanced labels\n",
        "print(\"Nuova distribuzione PPM Class:\", Counter(y_class2_decoded))\n",
        "\n",
        "\n",
        "# Usa i dati bilanciati\n",
        "X = X_resampled\n",
        "y_class1 = y_class1_resampled\n",
        "y_class2 = y_class2_decoded\n",
        "\n",
        "# Definizione dell'input\n",
        "inputs = Input(shape=(X.shape[1],))\n",
        "\n",
        "# Strati condivisi\n",
        "shared = Dense(512, activation='relu')(inputs)\n",
        "shared = BatchNormalization()(shared)\n",
        "shared = Dropout(0.3)(shared)\n",
        "shared = Dense(128, activation='relu')(shared)\n",
        "shared = BatchNormalization()(shared)\n",
        "shared = Dropout(0.3)(shared)\n",
        "\n",
        "# Ramo di regressione\n",
        "regression_output = Dense(1, name='regression_output')(shared)\n",
        "\n",
        "# Ramo di classificazione temp_humidity_class\n",
        "concat_th = Concatenate()([shared, regression_output])\n",
        "dense_th = Dense(32, activation='relu')(concat_th)\n",
        "temp_humidity_class_output = Dense(len(encoder_th.classes_), activation='softmax', name='temp_humidity_class_output')(dense_th)\n",
        "\n",
        "# Ramo di classificazione class_ppm\n",
        "concat_ppm = Concatenate()([shared, regression_output])\n",
        "dense_ppm = Dense(32, activation='relu')(concat_ppm)\n",
        "ppm_class_output = Dense(len(encoder_ppm.classes_), activation='softmax', name='ppm_class_output')(dense_ppm)\n",
        "\n",
        "# Creazione del modello\n",
        "model = Model(inputs=inputs, outputs=[regression_output, temp_humidity_class_output, ppm_class_output])\n",
        "\n",
        "# Compilazione\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss={'regression_output': 'mse',\n",
        "                    'temp_humidity_class_output': 'sparse_categorical_crossentropy',\n",
        "                    'ppm_class_output': 'sparse_categorical_crossentropy'},\n",
        "              loss_weights={\n",
        "                  'regression_output': 0.2,\n",
        "                  'temp_humidity_class_output': 2.1,\n",
        "                  'ppm_class_output': 1.0\n",
        "              },\n",
        "              metrics={'regression_output': 'mae',\n",
        "                       'temp_humidity_class_output': 'accuracy',\n",
        "                       'ppm_class_output': 'accuracy'})\n",
        "\n",
        "# Visualizza la struttura del modello\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(X_train,\n",
        "                    {'regression_output': y_reg_train,\n",
        "                     'temp_humidity_class_output': y_class_th_train,\n",
        "                     'ppm_class_output': y_class_ppm_train},\n",
        "                    validation_data=(X_test, {'regression_output': y_reg_test,\n",
        "                                              'temp_humidity_class_output': y_class_th_test,\n",
        "                                              'ppm_class_output': y_class_ppm_test}),\n",
        "                    epochs=10, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6eP1F1IToUs",
        "outputId": "387b7418-94cf-4ef9-f281-a1b17bc6ff30"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"Distribuzione Temp-Humidity Class:\")\n",
        "print(np.bincount(df_scaled['temp_humidity_class']))\n",
        "\n",
        "print(\"Distribuzione PPM Class:\")\n",
        "print(np.bincount(df_scaled['class_ppm']))\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "dummy_input = np.array([[23.20, 42]])  # Un input normalizzato di prova\n",
        "output = model.predict(dummy_input)\n",
        "\n",
        "print(\"PPM Prediction:\", output[0])\n",
        "print(\"Temp-Humidity Class Probabilities:\", output[1])\n",
        "print(\"PPM Class Probabilities:\", output[2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKTEX7H-ToUt"
      },
      "source": [
        "### Valutazione e grafici"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWSOKG1OToUt",
        "outputId": "7f6b9348-696a-42c2-9c0b-cae0f174fadb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"Media di X_train:\", np.mean(X_train, axis=0))\n",
        "print(\"Deviazione standard di X_train:\", np.std(X_train, axis=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "id": "ZqilaV94ToUt",
        "outputId": "d5654ca6-a7bc-4d8b-810e-4e182c7ed527"
      },
      "outputs": [],
      "source": [
        "# Grafico della perdita (loss)\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Andamento della Loss')\n",
        "plt.show()\n",
        "\n",
        "# Grafico dell'accuratezza per le due classificazioni\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(history.history['temp_humidity_class_output_accuracy'], label='Training Accuracy (temp_humidity)')\n",
        "plt.plot(history.history['val_temp_humidity_class_output_accuracy'], label='Validation Accuracy (temp_humidity)')\n",
        "plt.plot(history.history['ppm_class_output_accuracy'], label='Training Accuracy (ppm_class)')\n",
        "plt.plot(history.history['val_ppm_class_output_accuracy'], label='Validation Accuracy (ppm_class)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Andamento dell\\'Accuratezza')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfSjoMe1ToUu",
        "outputId": "d6b95fb9-2176-47d9-ed9a-b472afd67fc0"
      },
      "outputs": [],
      "source": [
        "model.save('model.h5')\n",
        "#files.download(\"my_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wKGoWvzqToUu",
        "outputId": "a3f94bc7-602d-47a5-fb2e-a62023464254"
      },
      "outputs": [],
      "source": [
        "# Load your model using custom_objects\n",
        "from tensorflow.keras.losses import MeanSquaredError, CategoricalCrossentropy # Import necessary classes\n",
        "from sklearn.preprocessing import MinMaxScaler  # Import MinMaxScaler\n",
        "\n",
        "model = keras.models.load_model('model.h5', custom_objects={\n",
        "    'mse': MeanSquaredError(),  # Specify 'mse' as MeanSquaredError\n",
        "    'categorical_crossentropy': CategoricalCrossentropy()  # Specify 'categorical_crossentropy'\n",
        "})\n",
        "\n",
        "# Assuming scaler_y is the scaler used for the target variable during training\n",
        "# If you don't have it, create a new one with the same feature range\n",
        "scaler_y = MinMaxScaler()\n",
        "scaler_y.fit(y_reg_train) # Replace y_reg_train with the original target training data if available\n",
        "\n",
        "\n",
        "# Make predictions on the test set\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "# Apply inverse_transform using the scaler fitted on the target variable (y_reg_train)\n",
        "Y_pred_reg = scaler_y.inverse_transform(Y_pred[0].reshape(-1, 1)) # Inverse transform the regression output\n",
        "\n",
        "# The rest of your code remains the same:\n",
        "output = Dense(1, activation='sigmoid', name='ppm_output')(X_test)\n",
        "\n",
        "plt.hist(Y_pred_reg, bins=50) # Use the inverse transformed regression output for the histogram\n",
        "plt.title(\"Distribuzione dei valori di PPM dopo lo scaling\")\n",
        "plt.show()\n",
        "print(\"Predizioni prima della trasformazione inversa:\", Y_pred[0][:10]) # Print the original regression output\n",
        "print(\"Predizioni dopo la trasformazione inversa:\", Y_pred_reg[:10]) # Print the inverse transformed output\n",
        "\n",
        "# Now you can plot the scatter plot using the inverse transformed regression output\n",
        "plt.scatter(y_reg_test, Y_pred_reg)\n",
        "plt.xlabel(\"Valori reali di PPM\")\n",
        "plt.ylabel(\"Valori predetti di PPM\")\n",
        "plt.title(\"Previsione vs Valore Reale\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qq934oDuToUv",
        "outputId": "551a5c2f-3d01-4852-d0ad-679b8fa7b7ec"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions\n",
        "Y_pred_train = model.predict(X_train)\n",
        "Y_pred_test = model.predict(X_test)\n",
        "\n",
        "# Access the regression output (first element of the prediction tuple)\n",
        "Y_pred_train_reg = Y_pred_train[0]\n",
        "Y_pred_test_reg = Y_pred_test[0]\n",
        "\n",
        "# Assuming y_reg_train and y_reg_test contain the actual target values\n",
        "Y_train = y_reg_train  # Assign y_reg_train to Y_train\n",
        "Y_test = y_reg_test   # Assign y_reg_test to Y_test\n",
        "\n",
        "\n",
        "# Scatter plot for training data\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(Y_train, Y_pred_train_reg, label='Training Data') # Changed to Y_pred_train_reg\n",
        "plt.plot([Y_train.min(), Y_train.max()], [Y_train.min(), Y_train.max()], 'k--', lw=2) # Ideal line\n",
        "plt.xlabel('Actual PPM')\n",
        "plt.ylabel('Predicted PPM')\n",
        "plt.title('Training Data: Actual vs. Predicted PPM')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Scatter plot for test data\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(Y_test, Y_pred_test_reg, label='Test Data') # Changed to Y_pred_test_reg\n",
        "plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'k--', lw=2) # Ideal line\n",
        "plt.xlabel('Actual PPM')\n",
        "plt.ylabel('Predicted PPM')\n",
        "plt.title('Test Data: Actual vs. Predicted PPM')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuxsWs-qToUv"
      },
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnFf2R98ToUv",
        "outputId": "aced607b-b769-48b3-f1c8-9fc865b70a0b"
      },
      "outputs": [],
      "source": [
        "model.save('model.h5')\n",
        "#files.download(\"model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4itloiqToUw",
        "outputId": "c5d116e2-d96f-4691-c592-431989534e26"
      },
      "outputs": [],
      "source": [
        "from tinymlgen import port\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define a sequential model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_shape=(2,))  # Input shape matches your data (temp, humidity)\n",
        "])\n",
        "\n",
        "# Porting the Keras model to C using tinymlgen\n",
        "c_code = port(model, pretty_print=True, optimize=[tf.lite.Optimize.DEFAULT])\n",
        "\n",
        "# Write the generated C code to a file\n",
        "open(\"model.h\", \"w\").write(c_code)\n",
        "print(c_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyIRpVB_ToUw",
        "outputId": "97316b51-d9f3-4cbd-daea-1b1f30d5ef1a"
      },
      "outputs": [],
      "source": [
        "# Enable TensorFlow 2\n",
        "#try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        " # %tensorflow_version 2.x\n",
        "#except Exception:\n",
        " # pass\n",
        "#from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "#model = load_model('model3.h5')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "#converter.representative_dataset = representative_dataset_gen\n",
        "converter.experimental_new_quantizer = True\n",
        "converter.experimental_new_converter = True\n",
        "tflite_float_model = converter.convert()\n",
        "\n",
        "# Show model size in KBs.\n",
        "float_model_size = len(tflite_float_model) / 1024\n",
        "open(\"PPM-MODEL.tflite\", \"wb\").write(tflite_float_model)\n",
        "print('Float model size = %dKBs.' % float_model_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm7PGs7GToUw",
        "outputId": "eb41ae28-c8ea-4a08-baef-4a5afe4b0482"
      },
      "outputs": [],
      "source": [
        "!apt install xxd\n",
        "!xxd -i PPM-MODEL.tflite > ppm_model.h\n",
        "! ls -lh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHWrdMMyToUw",
        "outputId": "0b3f281b-8fcb-479d-bba4-9b9cf12f94a1"
      },
      "outputs": [],
      "source": [
        "! pip install \"everywhereml>=0.2.32\"\n",
        "from everywhereml.code_generators.tensorflow import tf_porter\n",
        "from everywhereml.code_generators.tensorflow import convert_model\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# ... (your existing code for data loading, preprocessing, etc.) ...\n",
        "\n",
        "# Create a OneHotEncoder object\n",
        "encoder = OneHotEncoder(sparse_output=False) # sparse=False for dense output\n",
        "\n",
        "# Fit the encoder to your training labels and transform them\n",
        "Y_train_encoded = encoder.fit_transform(Y_train.reshape(-1, 1)) # Reshape to 2D\n",
        "\n",
        "# Now use the encoded labels in convert_model\n",
        "cpp_code = tf_porter(model, X_train, Y_train_encoded).to_cpp(instance_name=\"model_data\")\n",
        "c_header = convert_model(model, X_train, Y_train_encoded, model_name='model_data')\n",
        "\n",
        "open(\"ppm.h\", \"w\").write(c_header)\n",
        "print(c_header)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
